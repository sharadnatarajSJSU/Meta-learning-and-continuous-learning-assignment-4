{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSbhwIhk1hG0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.003\n",
        "meta_step_size = 0.25\n",
        "\n",
        "inner_batch_size = 25\n",
        "eval_batch_size = 25\n",
        "\n",
        "meta_iters = 2000\n",
        "eval_iters = 5\n",
        "inner_iters = 4\n",
        "\n",
        "eval_interval = 1\n",
        "train_shots = 20\n",
        "shots = 5\n",
        "classes = 5\n"
      ],
      "metadata": {
        "id": "JckXLwas1r54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Dataset:\n",
        "    # This class will facilitate the creation of a few-shot dataset\n",
        "    # from the Omniglot dataset that can be sampled from quickly while also\n",
        "    # allowing to create new labels at the same time.\n",
        "    def __init__(self, training):\n",
        "        # Download the tfrecord files containing the omniglot data and convert to a\n",
        "        # dataset.\n",
        "        split = \"train\" if training else \"test\"\n",
        "        ds = tfds.load(\"omniglot\", split=split, as_supervised=True, shuffle_files=False)\n",
        "        # Iterate over the dataset to get each individual image and its class,\n",
        "        # and put that data into a dictionary.\n",
        "        self.data = {}\n",
        "\n",
        "        def extraction(image, label):\n",
        "            # This function will shrink the Omniglot images to the desired size,\n",
        "            # scale pixel values and convert the RGB image to grayscale\n",
        "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "            image = tf.image.rgb_to_grayscale(image)\n",
        "            image = tf.image.resize(image, [28, 28])\n",
        "            return image, label\n",
        "\n",
        "        for image, label in ds.map(extraction):\n",
        "            image = image.numpy()\n",
        "            label = str(label.numpy())\n",
        "            if label not in self.data:\n",
        "                self.data[label] = []\n",
        "            self.data[label].append(image)\n",
        "        self.labels = list(self.data.keys())\n",
        "\n",
        "    def get_mini_dataset(\n",
        "        self, batch_size, repetitions, shots, num_classes, split=False\n",
        "    ):\n",
        "        temp_labels = np.zeros(shape=(num_classes * shots))\n",
        "        temp_images = np.zeros(shape=(num_classes * shots, 28, 28, 1))\n",
        "        if split:\n",
        "            test_labels = np.zeros(shape=(num_classes))\n",
        "            test_images = np.zeros(shape=(num_classes, 28, 28, 1))\n",
        "\n",
        "        # Get a random subset of labels from the entire label set.\n",
        "        label_subset = random.choices(self.labels, k=num_classes)\n",
        "        for class_idx, class_obj in enumerate(label_subset):\n",
        "            # Use enumerated index value as a temporary label for mini-batch in\n",
        "            # few shot learning.\n",
        "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
        "            # If creating a split dataset for testing, select an extra sample from each\n",
        "            # label to create the test dataset.\n",
        "            if split:\n",
        "                test_labels[class_idx] = class_idx\n",
        "                images_to_split = random.choices(\n",
        "                    self.data[label_subset[class_idx]], k=shots + 1\n",
        "                )\n",
        "                test_images[class_idx] = images_to_split[-1]\n",
        "                temp_images[\n",
        "                    class_idx * shots : (class_idx + 1) * shots\n",
        "                ] = images_to_split[:-1]\n",
        "            else:\n",
        "                # For each index in the randomly selected label_subset, sample the\n",
        "                # necessary number of images.\n",
        "                temp_images[\n",
        "                    class_idx * shots : (class_idx + 1) * shots\n",
        "                ] = random.choices(self.data[label_subset[class_idx]], k=shots)\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(\n",
        "            (temp_images.astype(np.float32), temp_labels.astype(np.int32))\n",
        "        )\n",
        "        dataset = dataset.shuffle(100).batch(batch_size).repeat(repetitions)\n",
        "        if split:\n",
        "            return dataset, test_images, test_labels\n",
        "        return dataset\n",
        "\n",
        "\n",
        "import urllib3\n",
        "\n",
        "urllib3.disable_warnings()  # Disable SSL warnings that may happen during download.\n",
        "train_dataset = Dataset(training=True)\n",
        "test_dataset = Dataset(training=False)\n"
      ],
      "metadata": {
        "id": "nPxzEm0P1tLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial16/\"\n",
        "# Files to download\n",
        "pretrained_files = [\n",
        "    \"ProtoNet.ckpt\",\n",
        "    \"ProtoMAML.ckpt\",\n",
        "    \"tensorboards/ProtoNet/events.out.tfevents.ProtoNet\",\n",
        "    \"tensorboards/ProtoMAML/events.out.tfevents.ProtoMAML\",\n",
        "    \"protomaml_fewshot.json\",\n",
        "    \"protomaml_svhn_fewshot.json\",\n",
        "]\n",
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(\"Downloading %s...\" % file_url)\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\n",
        "                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n",
        "                e,\n",
        "            )"
      ],
      "metadata": {
        "id": "PL3QlkJw16pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading CIFAR100 dataset\n",
        "cifar_train_set = CIFAR100(root=DATASET_PATH, train=True, download=True, transform=transforms.ToTensor())\n",
        "cifar_test_set = CIFAR100(root=DATASET_PATH, train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "0pfgdb6e18M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some examples\n",
        "NUM_IMAGES = 12\n",
        "cifar_images = [cifar_train_set[np.random.randint(len(cifar_train_set))][0] for idx in range(NUM_IMAGES)]\n",
        "cifar_images = torch.stack(cifar_images, dim=0)\n",
        "img_grid = torchvision.utils.make_grid(cifar_images, nrow=6, normalize=True, pad_value=0.9)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Image examples of the CIFAR100 dataset\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "U2q1BlpL1-T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging original training and test set\n",
        "cifar_all_images = np.concatenate([cifar_train_set.data, cifar_test_set.data], axis=0)\n",
        "cifar_all_targets = torch.LongTensor(cifar_train_set.targets + cifar_test_set.targets)"
      ],
      "metadata": {
        "id": "3o7zxmPY1-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(data.Dataset):\n",
        "    def __init__(self, imgs, targets, img_transform=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            imgs - Numpy array of shape [N,32,32,3] containing all images.\n",
        "            targets - PyTorch array of shape [N] containing all labels.\n",
        "            img_transform - A torchvision transformation that should be applied\n",
        "                            to the images before returning. If none, no transformation\n",
        "                            is applied.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.img_transform = img_transform\n",
        "        self.imgs = imgs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.imgs[idx], self.targets[idx]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.imgs.shape[0]"
      ],
      "metadata": {
        "id": "Z86HUbs42BMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(0)  # Set seed for reproducibility\n",
        "classes = torch.randperm(100)  # Returns random permutation of numbers 0 to 99\n",
        "train_classes, val_classes, test_classes = classes[:80], classes[80:90], classes[90:]"
      ],
      "metadata": {
        "id": "NiojOJAt2COr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing validation and test classes\n",
        "idx_to_class = {val: key for key, val in cifar_train_set.class_to_idx.items()}\n",
        "print(\"Validation classes:\", [idx_to_class[c.item()] for c in val_classes])\n",
        "print(\"Test classes:\", [idx_to_class[c.item()] for c in test_classes])"
      ],
      "metadata": {
        "id": "b2xlsJy42Dok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}